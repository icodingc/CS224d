{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "import nltk\n",
    "import jieba\n",
    "vocabulary_size = 800\n",
    "unknown_token = u\"U\"\n",
    "sentence_start_token = u\"S\"\n",
    "sentence_end_token = u\"E\"\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "jieba 分词"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read txt file...\n"
     ]
    }
   ],
   "source": [
    "print \"Read txt file...\"\n",
    "with open(\"data/ppd/input.txt\",\"rb\") as f:\n",
    "    reader = f.readlines()\n",
    "    sentences = [list(jieba.cut(x)) for x in reader if len(x) > 3]\n",
    "#     sentences=[\"%s %s %s\" % (sentence_start_token, x, sentence_end_token) for x in reader]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3842\n"
     ]
    }
   ],
   "source": [
    "print len(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "raw= sentences[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# add S E\n",
    "for a in sentences:\n",
    "    a.insert(0,sentence_start_token)\n",
    "    a.insert(len(a)-1,sentence_end_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S 只好 装 得 放荡 E \r\n",
      "S 飞来飞去 E \r\n",
      "S 我 飞来飞去 E \r\n",
      "S 满怀希望 E \r\n",
      "S 我 像 一只 小鸟 E \r\n",
      "S 我 感觉 不到 倦意 E \r\n",
      "S 却 又 无处可去 E \r\n",
      "S 空虚 把 我 仍 在 街上 E \r\n",
      "S 像 个 病人 逃避 死亡 E \r\n",
      "S 这里 适合 游荡 E \r\n"
     ]
    }
   ],
   "source": [
    "for a in sentences[50:60]:\n",
    "    for w in a:\n",
    "        print w,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S 我 真的 需要 你 E \r\n",
      "S 现在 我 觉得 有些 孤单 E \r\n",
      "S 悲哀 的 自我 有些 辛酸 E \r\n",
      "S 没有 爱 也 没有 存款 E \r\n",
      "S 只有 去 幻想 才能 感到 一丝 温暖 E \r\n",
      "S 每天 早晨 我数 一二三 E \r\n",
      "S 爬 起床 来 看见 阳光灿烂 E \r\n",
      "S 大街 上 落叶 纷纷 E \r\n",
      "S 商店 里 放 着 怀旧 歌曲 E \r\n",
      "S 我 真的 真的 需要 E \r\n",
      "S 我 真的 需要 你 E \r\n",
      "S 当 夜晚 降临 繁星 满天 E \r\n",
      "S 我 灵魂 的 影子 靠 在 那个 墙上 E \r\n",
      "S 没有 脸 也 没有 心脏 E \r\n",
      "S 在 长安街 上 像 朵 苍白 的 花 E \r\n",
      "S 我 倾听 着 静脉 里 血 的 流淌 E \r\n",
      "S 就 像 那 昨夜 漫长 冷漠 的 细雨 E \r\n",
      "S 我 睁 着眼 许多 门 在 面前 紧闭 E \r\n",
      "S 现在 我 真的 那么 真的 E \r\n",
      "S 我 真的 我 真的 需要 E \r\n",
      "S 我 真的 需要 你 E \r\n",
      "S 每天 我 疲惫 地 回到 家里 E \r\n",
      "S 躺 在 床上 听 着 收音机 里 的 浪漫 E \r\n",
      "S 回忆 着 过去 的 幸福 E \r\n",
      "S 呢喃 着 现实 的 渺茫   E \r\n",
      "S 爱情 是 放在 兜里 的 一颗 炸弹 E \r\n",
      "S 生活 像件 背心 破烂不堪 E \r\n",
      "S 现在 我 不再 需要 啤酒 和 上帝 E  \n"
     ]
    }
   ],
   "source": [
    "# tostring\n",
    "for a in sentences:\n",
    "    for w in a:\n",
    "        print w,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<type 'list'>\n",
      "<type 'list'>\n",
      "<type 'list'>\n"
     ]
    }
   ],
   "source": [
    "print type(sentences)\n",
    "print type(sentences[0])\n",
    "print type(sentences[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'decode'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-61-8b3becab86ab>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtokenized_sentences\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mnltk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mword_tokenize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msent\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'utf-8'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0msent\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msentences\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'decode'"
     ]
    }
   ],
   "source": [
    "# already is list.type ,do not use word_tokenize\n",
    "tokenized_sentences = [nltk.word_tokenize(sent.decode('utf-8')) for sent in sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S 我 真 的 需 要 你 E\n"
     ]
    }
   ],
   "source": [
    "for a in tokenized_sentences[0]:print a,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S 他 有 一个 美满 的 好 生活 E \r\n"
     ]
    }
   ],
   "source": [
    "for a in sentences[100]:print a,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "word_freq = nltk.FreqDist(itertools.chain(*sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "坚定 1\n",
      "喝完 1\n",
      "认不出 2\n",
      "不治之症 1\n",
      "乐园 1\n",
      "这条 6\n",
      "什么样 4\n",
      "般 9\n",
      "发生 7\n",
      "如同 7\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3283"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in word_freq.keys()[10:20]:\n",
    "    print i,word_freq[i]\n",
    "len(word_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vocab = word_freq.most_common(3283)\n",
    "index_to_word = [x[0] for x in vocab]\n",
    "index_to_word.append(unknown_token)\n",
    "word_to_index = dict([(w,i) for i,w in enumerate(index_to_word)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 感觉\n",
      "21 都\n",
      "22 知道\n",
      "23 生命\n",
      "24 不\n",
      "25 爱\n",
      "26 自己\n",
      "27 有\n",
      "28 地\n",
      "29 会\n"
     ]
    }
   ],
   "source": [
    "for i in xrange(20,30):\n",
    "    print i,index_to_word[i]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i, sent in enumerate(sentences):\n",
    "    sentences[i] = [w if w in word_to_index else unknown_token for w in sent]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Example sentence: 'S 我 真 的 需 要 你\r\n",
      " E'\n",
      "\n",
      "Example sentence after Pre-processing: '[u'S', u'\\u6211', u'\\u771f', u'\\u7684', u'\\u9700', u'\\u8981', u'\\u4f60', u'E']'\n"
     ]
    }
   ],
   "source": [
    "print \"\\nExample sentence: '%s'\" % sentences[0]\n",
    "print \"\\nExample sentence after Pre-processing: '%s'\" % tokenized_sentences[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "X_train = np.asarray([ np.asarray([word_to_index[w] for w in sent[:-1]]) for sent in sentences])\n",
    "y_train = np.asarray([ np.asarray([word_to_index[w] for w in sent[1:]]) for sent in sentences])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3842L,)\n",
      "(3842L,)\n"
     ]
    }
   ],
   "source": [
    "print X_train.shape\n",
    "print y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E\n"
     ]
    }
   ],
   "source": [
    "print index_to_word[141]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S 我 是 你 弱小 的 孩子 E \r\n",
      "[  1   4  14   5 733   3 103   0]\n",
      "[  4  14   5 733   3 103   0   2]\n"
     ]
    }
   ],
   "source": [
    "for a in sentences[1000]:print a,\n",
    "print X_train[1000]\n",
    "print y_train[1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from rnnlm import RNNLM\n",
    "hdim = 100\n",
    "np.random.seed(10)\n",
    "L0 = np.zeros((3284,hdim))\n",
    "model = RNNLM(L0,U0=L0,alpha=0.01,rseed=10,bptt=3)\n",
    "# model.grad_check(np.array([1,2,3]),np.array([2,3,4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 3842 train example\n",
      "Begin SGD...\n",
      "  Seen 0 in 0.00 s\n",
      "  [0]: mean loss 8.13835\n",
      "  Seen 10000 in 312.42 s\n",
      "  [10000]: mean loss 4.60573\n",
      "  [15368]: mean loss 4.53843\n",
      "SGD complete: 15368 examples in 514.04 seconds.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(0, 8.1383533367346921),\n",
       " (10000, 4.6057307216439938),\n",
       " (15368, 4.5384317953327509)]"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from rnnlm import RNNLM\n",
    "epoch = 4\n",
    "nn = len(y_train)\n",
    "X = X_train[:nn]\n",
    "Y = y_train[:nn]\n",
    "idxiter = np.random.permutation(range(nn)*epoch)\n",
    "print \"Using %d train example\" % nn\n",
    "\n",
    "model.train_sgd(X,Y,idxiter=idxiter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cPickle as pickle\n",
    "def save_(name,p):\n",
    "    with open(name,\"w\") as f:pickle.dump(p, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "save_(\"wf.L.npy\", model.sparams.L)\n",
    "save_(\"wf.U.npy\", model.params.U)\n",
    "save_(\"wf.H.npy\", model.params.H)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27.985226324\n",
      "S 我 的 感觉 紧紧 永生 E\n"
     ]
    }
   ],
   "source": [
    "def seq_to_words(seq):\n",
    "    return [index_to_word[s] for s in seq]\n",
    "    \n",
    "seq, J = model.generate_sequence(word_to_index[sentence_start_token], \n",
    "                                 word_to_index[sentence_end_token], \n",
    "                                 maxlen=80)\n",
    "print J\n",
    "# print seq\n",
    "print \" \".join(seq_to_words(seq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S 辉煌 那 现实   到底 带你去 恋人 E\n"
     ]
    }
   ],
   "source": [
    "print \" \".join(seq_to_words(model.generate_sequence(word_to_index[sentence_start_token], \n",
    "                                 word_to_index[sentence_end_token], \n",
    "                                 maxlen=80)[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fg = lambda :\" \".join(seq_to_words(model.generate_sequence(word_to_index[sentence_start_token], \n",
    "                                 word_to_index[sentence_end_token], \n",
    "                                 maxlen=80)[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S 我 的 好点 再也 了 E\n",
      "S 眩晕 你 没有 会 地方 杀人 E\n",
      "S 我 夜里 你 怎样 我 低保金 更 蓝天 走来 的 街道 如同 E\n",
      "S 就 相信 青春 幸福 E\n",
      "S 我 再见 有意思 你 像 幻觉 早点 E\n",
      "S 轻轻地 无论 U 的 我们 E\n",
      "S 是 那 我 奇幻 青稞 我 一种 窒息 E\n",
      "S 我 明天 一 的 孩子 神往 不想 E\n",
      "S 幻觉 你 见 最后 我 这里 E\n",
      "S 车里 一天 我 不再 的 了 公主 E\n"
     ]
    }
   ],
   "source": [
    "for i in xrange(10):\n",
    "    print fg()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
